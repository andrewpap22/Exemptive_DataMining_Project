{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andreas Pappas \n",
    "# ID: 1115201500201 \n",
    "\n",
    "## Exemptive Data Mining Project for spring-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and foremost we'll load the libraries needed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import sys\n",
    "import unidecode\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split as cv\n",
    "from sklearn import svm # Support Vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest\n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the dataset we'll work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "train_data_file = path + 'train.csv'\n",
    "test_data_file = path + 'impermium_verification_set.csv'\n",
    "eval_data_file = path + 'impermium_verification_labels.csv'\n",
    "\n",
    "# Now that we got the paths, we'll load the data into pandas dataframe:\n",
    "\n",
    "train_data = pd.read_csv(train_data_file)\n",
    "test_data = pd.read_csv(test_data_file)\n",
    "eval_data = pd.read_csv(eval_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"\n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...\n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...\n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120603163526Z</td>\n",
       "      <td>\"like this if you are a tribe fan\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120531215447Z</td>\n",
       "      <td>\"you're idiot.......................\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120823164228Z</td>\n",
       "      <td>\"I am a woman Babs, and the only \"war on women...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120826010752Z</td>\n",
       "      <td>\"WOW &amp; YOU BENEFITTED SO MANY WINS THIS YEAR F...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120602223825Z</td>\n",
       "      <td>\"haha green me red you now loser whos winning ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Insult             Date  \\\n",
       "0   1     NaN  20120603163526Z   \n",
       "1   2     NaN  20120531215447Z   \n",
       "2   3     NaN  20120823164228Z   \n",
       "3   4     NaN  20120826010752Z   \n",
       "4   5     NaN  20120602223825Z   \n",
       "\n",
       "                                             Comment        Usage  \n",
       "0                 \"like this if you are a tribe fan\"  PrivateTest  \n",
       "1              \"you're idiot.......................\"  PrivateTest  \n",
       "2  \"I am a woman Babs, and the only \"war on women...  PrivateTest  \n",
       "3  \"WOW & YOU BENEFITTED SO MANY WINS THIS YEAR F...  PrivateTest  \n",
       "4  \"haha green me red you now loser whos winning ...  PrivateTest  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20120603163526Z</td>\n",
       "      <td>\"like this if you are a tribe fan\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20120531215447Z</td>\n",
       "      <td>\"you're idiot.......................\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20120823164228Z</td>\n",
       "      <td>\"I am a woman Babs, and the only \"war on women...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20120826010752Z</td>\n",
       "      <td>\"WOW &amp; YOU BENEFITTED SO MANY WINS THIS YEAR F...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20120602223825Z</td>\n",
       "      <td>\"haha green me red you now loser whos winning ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Insult             Date  \\\n",
       "0   1       0  20120603163526Z   \n",
       "1   2       1  20120531215447Z   \n",
       "2   3       1  20120823164228Z   \n",
       "3   4       1  20120826010752Z   \n",
       "4   5       1  20120602223825Z   \n",
       "\n",
       "                                             Comment        Usage  \n",
       "0                 \"like this if you are a tribe fan\"  PrivateTest  \n",
       "1              \"you're idiot.......................\"  PrivateTest  \n",
       "2  \"I am a woman Babs, and the only \"war on women...  PrivateTest  \n",
       "3  \"WOW & YOU BENEFITTED SO MANY WINS THIS YEAR F...  PrivateTest  \n",
       "4  \"haha green me red you now loser whos winning ...  PrivateTest  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Cleaning of data \n",
    "\n",
    "*Now that we loaded our data we're going to clean them, so they're in a more readable form for our algorithms, and so we get a better precision and understanding of the data* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Load the cleaned words\n",
    "########################################\n",
    "\n",
    "cl_path = 'cleanwords.txt'\n",
    "clean_word_dict = {}\n",
    "with open(cl_path, 'r', encoding='utf-8') as cl:\n",
    "    for line in cl:\n",
    "        line = line.strip('\\n')\n",
    "        typo, correct = line.split(',')\n",
    "        clean_word_dict[typo] = correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Cleaned.\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## process texts in datasets\n",
    "########################################\n",
    "print('Processing text dataset')\n",
    "# Regex to remove all Non-Alpha Numeric and space\n",
    "special_character_removal=re.compile(r'[^?!.,:a-z\\d ]',re.IGNORECASE)\n",
    "\n",
    "# regex to replace all numerics\n",
    "replace_numbers=re.compile(r'\\d+',re.IGNORECASE)\n",
    "word_count_dict = defaultdict(int)\n",
    "\n",
    "def clean_text(text, remove_stopwords=True, stem_words=True, count_null_words=True, clean_wiki_tokens=True):\n",
    "    # Clean the text, with the option to remove stopwords and to stem words.\n",
    "    # dirty words\n",
    "    #non-ASCII characters to their closest ASCII equivalent automatically.\n",
    "    #text = unidecode.unidecode(text) \n",
    "\n",
    "    text = text.lower() #lower all text\n",
    "    text = re.sub(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", \"\", text)\n",
    "    text = re.sub(r\"(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\xa|\\\\xc|\\\\|\\\\xe|\\\\u\", \" \", text)\n",
    "    # remove @mentions\n",
    "    text = re.sub('@[A-Za-z0-9]+', '', text)\n",
    "    \n",
    "    if clean_wiki_tokens:\n",
    "        # Drop the image\n",
    "        text = re.sub(r\"image:[a-zA-Z0-9]*\\.jpg\", \" \", text)\n",
    "        text = re.sub(r\"image:[a-zA-Z0-9]*\\.png\", \" \", text)\n",
    "        text = re.sub(r\"image:[a-zA-Z0-9]*\\.gif\", \" \", text)\n",
    "        text = re.sub(r\"image:[a-zA-Z0-9]*\\.bmp\", \" \", text)\n",
    "\n",
    "        # Drop css\n",
    "        text = re.sub(r\"#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})\", \" \",text)\n",
    "        text = re.sub(r\"\\{\\|[^\\}]*\\|\\}\", \" \", text)\n",
    "        \n",
    "        # Clean templates\n",
    "        text = re.sub(r\"\\[?\\[user:.*\\]\", \" \", text)\n",
    "        text = re.sub(r\"\\[?\\[user:.*\\|\", \" \", text)        \n",
    "        text = re.sub(r\"\\[?\\[wikipedia:.*\\]\", \" \", text)\n",
    "        text = re.sub(r\"\\[?\\[wikipedia:.*\\|\", \" \", text)\n",
    "        text = re.sub(r\"\\[?\\[special:.*\\]\", \" \", text)\n",
    "        text = re.sub(r\"\\[?\\[special:.*\\|\", \" \", text)\n",
    "        text = re.sub(r\"\\[?\\[category:.*\\]\", \" \", text)\n",
    "        text = re.sub(r\"\\[?\\[category:.*\\|\", \" \", text)\n",
    "    \n",
    "    for typo, correct in clean_word_dict.items():\n",
    "        text = re.sub(typo, \" \" + correct + \" \", text)\n",
    "\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\?\", \" ? \", text)\n",
    "    text = re.sub(r\"\\!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\\"\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = replace_numbers.sub(' ', text)\n",
    "    #text = special_character_removal.sub('',text)\n",
    "\n",
    "    if count_null_words:\n",
    "        text = text.split()\n",
    "        for t in text:\n",
    "            word_count_dict[t] += 1\n",
    "        text = \" \".join(text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "\n",
    "    return (text)\n",
    "\n",
    "list_sentences_train = train_data[\"Comment\"].fillna(\"noComment\").values\n",
    "list_sentences_test = test_data[\"Comment\"].fillna(\"noComment\").values\n",
    "list_sentences_eval = eval_data[\"Comment\"].fillna(\"noComment\").values\n",
    "\n",
    "train_comments = [clean_text(text) for text in list_sentences_train]\n",
    "test_comments = [clean_text(text) for text in list_sentences_test]\n",
    "eval_comments = [clean_text(text) for text in list_sentences_eval]\n",
    "\n",
    "print(\"Cleaned.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we cleaned our data, we'll create new files to seperate uncleaned data from cleaned data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Comment'] = train_comments\n",
    "test_data['Comment'] = test_comments\n",
    "eval_data['Comment'] = eval_comments\n",
    "\n",
    "#save the cleaned data\n",
    "train_data.to_csv('data/cleaned_train.csv', index = False)\n",
    "test_data.to_csv('data/cleaned_test.csv', index = False)\n",
    "eval_data.to_csv('data/cleaned_eval.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the cleaned data into pandas dataframe:\n",
    "\n",
    "cl_train_df = pd.read_csv('data/cleaned_train.csv')\n",
    "cl_test_df = pd.read_csv('data/cleaned_test.csv')\n",
    "cl_eval_df = pd.read_csv('data/cleaned_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>you fuck your dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>i realli do not understand your point it seem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a major of canadian can and has been wrong bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>listen if you dont wanna get marri to a man or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>c xe c b u ea n xu u ed ng u u b u eddng bi u ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                                  you fuck your dad\n",
       "1       0  20120528192215Z  i realli do not understand your point it seem ...\n",
       "2       0              NaN  a major of canadian can and has been wrong bef...\n",
       "3       0              NaN  listen if you dont wanna get marri to a man or...\n",
       "4       0  20120619094753Z  c xe c b u ea n xu u ed ng u u b u eddng bi u ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120603163526Z</td>\n",
       "      <td>like this if you are a tribe fan</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120531215447Z</td>\n",
       "      <td>you are idiot</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120823164228Z</td>\n",
       "      <td>i am a woman babs and the only war on women i ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120826010752Z</td>\n",
       "      <td>wow &amp; you benefitted so many wins this year fr...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20120602223825Z</td>\n",
       "      <td>haha green me red you now loser whos winning n...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Insult             Date  \\\n",
       "0   1     NaN  20120603163526Z   \n",
       "1   2     NaN  20120531215447Z   \n",
       "2   3     NaN  20120823164228Z   \n",
       "3   4     NaN  20120826010752Z   \n",
       "4   5     NaN  20120602223825Z   \n",
       "\n",
       "                                             Comment        Usage  \n",
       "0                   like this if you are a tribe fan  PrivateTest  \n",
       "1                                      you are idiot  PrivateTest  \n",
       "2  i am a woman babs and the only war on women i ...  PrivateTest  \n",
       "3  wow & you benefitted so many wins this year fr...  PrivateTest  \n",
       "4  haha green me red you now loser whos winning n...  PrivateTest  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20120603163526Z</td>\n",
       "      <td>like this if you are a tribe fan</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20120531215447Z</td>\n",
       "      <td>you are idiot</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20120823164228Z</td>\n",
       "      <td>i am a woman babs and the only war on women i ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20120826010752Z</td>\n",
       "      <td>wow &amp; you benefitted so many wins this year fr...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20120602223825Z</td>\n",
       "      <td>haha green me red you now loser whos winning n...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Insult             Date  \\\n",
       "0   1       0  20120603163526Z   \n",
       "1   2       1  20120531215447Z   \n",
       "2   3       1  20120823164228Z   \n",
       "3   4       1  20120826010752Z   \n",
       "4   5       1  20120602223825Z   \n",
       "\n",
       "                                             Comment        Usage  \n",
       "0                   like this if you are a tribe fan  PrivateTest  \n",
       "1                                      you are idiot  PrivateTest  \n",
       "2  i am a woman babs and the only war on women i ...  PrivateTest  \n",
       "3  wow & you benefitted so many wins this year fr...  PrivateTest  \n",
       "4  haha green me red you now loser whos winning n...  PrivateTest  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So as we can see the Comments are perfectly cleaned now, compared to the firstly given csv's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cl_train_df['Comment'], \n",
    "                                                    cl_train_df['Insult'], \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with the classic NaiveBayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments to word vectors using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,1) #we will use bigrams later on the improvement part\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3157, 222)\n",
      "(790, 222)\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer(encoding='utf-8',\n",
    "                      ngram_range=ngram_range,\n",
    "                     stop_words=None,\n",
    "                     max_df=max_df,\n",
    "                     min_df=min_df,\n",
    "                     max_features=max_features)\n",
    "        \n",
    "bow_train = bow.fit_transform(X_train.astype('U')).toarray()\n",
    "print(bow_train.shape)\n",
    "bow_test = bow.fit_transform(X_test.astype('U')).toarray()\n",
    "print(bow_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic NaiveBayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So at this point we will not tune any hyperparameter and we will pass the word vectors produced by the CountVectorizer as asked in the project definition. \n",
    "**Later on we will improve the NaiveBayes and compare the results for each improvement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbc = MultinomialNB(alpha=0) #alpha = 0 means we will not use laplace smoothing in this step\n",
    "mnbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbc.fit(bow_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbc_pred = mnbc.predict(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.7700348432055749\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(Y_train, mnbc.predict(bow_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: \n",
      "0.649367088607595\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(Y_test, mnbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       585\n",
      "           1       0.39      0.64      0.49       205\n",
      "\n",
      "    accuracy                           0.65       790\n",
      "   macro avg       0.62      0.65      0.61       790\n",
      "weighted avg       0.72      0.65      0.67       790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(Y_test,mnbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic Naïve Bayes</td>\n",
       "      <td>0.770035</td>\n",
       "      <td>0.649367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Training Set Accuracy  Test Set Accuracy\n",
       "0  Basic Naïve Bayes               0.770035           0.649367"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "     'Model': 'Basic Naïve Bayes',\n",
    "     'Training Set Accuracy': accuracy_score(Y_train, mnbc.predict(bow_train)),\n",
    "     'Test Set Accuracy': accuracy_score(Y_test, mnbc_pred)\n",
    "}\n",
    "\n",
    "df_models_mnbc = pd.DataFrame(d, index=[0])\n",
    "df_models_mnbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_models_mnbc.pickle', 'wb') as output: \n",
    "    pickle.dump(df_models_mnbc, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we got the accuracy and the F1-Score of the basic NaiveBayes, we will improve it by doing lemmatization, removing stop words, using bigrams, and using laplace Smoothing to check if we're going to get any better results!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the lemmatizer into an object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN order to lemmatize, we have to iterate through every word:\n",
    "\n",
    "nrows = len(train_data)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = train_data.loc[row]['Comment']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/andrewpap22/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the stop words list\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))\n",
    "stop_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StopWord eating a meal'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To remove the stop words, we'll handle a regular expression only detecting whole words, as seen in the following example:\n",
    "\n",
    "example = \"me eating a meal\"\n",
    "word = \"me\"\n",
    "\n",
    "# The regular expression is:\n",
    "regex = r\"\\b\" + word + r\"\\b\"  # we need to build it like that to work properly\n",
    "\n",
    "re.sub(regex, \"StopWord\", example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now loop through all the stop words:\n",
    "for stop_word in stop_words:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    train_data['Comment'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>[fuck, dad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>[realli, understand, point, seem, mix, appl, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[major, canadian, wrong, befor, n, nunless, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[listen, dont, wan, na, get, marri, man, woman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>[c, xe, c, b, u, ea, n, xu, u, ed, ng, u, u, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                                        [fuck, dad]\n",
       "1       0  20120528192215Z  [realli, understand, point, seem, mix, appl, o...\n",
       "2       0              NaN  [major, canadian, wrong, befor, n, nunless, su...\n",
       "3       0              NaN  [listen, dont, wan, na, get, marri, man, woman...\n",
       "4       0  20120619094753Z  [c, xe, c, b, u, ea, n, xu, u, ed, ng, u, u, b..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have done lemmatization and have removed the stopwords, we'll tune in NaiveBayes again with the newly cleaned data, using bigrams this time and applying Laplace Smoothing by setting alpha = 0.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, labels_train, labels_test = train_test_split(train_data['Comment'], \n",
    "                                                    train_data['Insult'], \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>you fuck your dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>i realli do not understand your point it seem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a major of canadian can and has been wrong bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>listen if you dont wanna get marri to a man or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>c xe c b u ea n xu u ed ng u u b u eddng bi u ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                                  you fuck your dad\n",
       "1       0  20120528192215Z  i realli do not understand your point it seem ...\n",
       "2       0              NaN  a major of canadian can and has been wrong bef...\n",
       "3       0              NaN  listen if you dont wanna get marri to a man or...\n",
       "4       0  20120619094753Z  c xe c b u ea n xu u ed ng u u b u eddng bi u ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range2 = (1,2) #using bigrams this time!\n",
    "min_df2 = 10\n",
    "max_df2 = 1.\n",
    "max_features2 = 222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3157, 222)\n",
      "(790, 222)\n"
     ]
    }
   ],
   "source": [
    "bow2 = CountVectorizer(encoding='utf-8',\n",
    "                     ngram_range=ngram_range2,\n",
    "                     stop_words=stop_words,\n",
    "                     max_df=max_df2,\n",
    "                     min_df=min_df2,\n",
    "                     max_features=max_features2)\n",
    "\n",
    "bow_train2 = bow2.fit_transform(x_train.astype('U')).toarray()\n",
    "print(bow_train2.shape)\n",
    "bow_test2 = bow2.fit_transform(x_test.astype('U')).toarray()\n",
    "print(bow_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbc2 = MultinomialNB(alpha=0.01) #using Laplace Smoothing with value of 22\n",
    "mnbc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbc2.fit(bow_train2, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbc_pred2 = mnbc2.predict(bow_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.8150142540386442\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, mnbc2.predict(bow_train2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: \n",
      "0.6594936708860759\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, mnbc_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78       585\n",
      "           1       0.28      0.20      0.23       205\n",
      "\n",
      "    accuracy                           0.66       790\n",
      "   macro avg       0.51      0.51      0.51       790\n",
      "weighted avg       0.62      0.66      0.64       790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,mnbc_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improved Naïve Bayes</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.659494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training Set Accuracy  Test Set Accuracy\n",
       "0  Improved Naïve Bayes               0.815014           0.659494"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "     'Model': 'Improved Naïve Bayes',\n",
    "     'Training Set Accuracy': accuracy_score(labels_train, mnbc2.predict(bow_train2)),\n",
    "     'Test Set Accuracy': accuracy_score(labels_test, mnbc_pred2)\n",
    "}\n",
    "\n",
    "df_models_mnbc2 = pd.DataFrame(d, index=[0])\n",
    "df_models_mnbc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_models_mnbc2.pickle', 'wb') as output: \n",
    "    pickle.dump(df_models_mnbc2, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pickles = \"/home/andrewpap22/Desktop/dataMining_MainProject/\"\n",
    "\n",
    "list_pickles = [\n",
    "    \"df_models_mnbc.pickle\",\n",
    "    \"df_models_mnbc2.pickle\"\n",
    "]\n",
    "\n",
    "df_summary = pd.DataFrame()\n",
    "\n",
    "for pickle_ in list_pickles:\n",
    "    \n",
    "    path = path_pickles + pickle_\n",
    "    \n",
    "    with open(path, 'rb') as data:\n",
    "        df = pickle.load(data)\n",
    "\n",
    "    df_summary = df_summary.append(df)\n",
    "\n",
    "df_summary = df_summary.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic Naïve Bayes</td>\n",
       "      <td>0.770035</td>\n",
       "      <td>0.649367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Improved Naïve Bayes</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.659494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training Set Accuracy  Test Set Accuracy\n",
       "0     Basic Naïve Bayes               0.770035           0.649367\n",
       "1  Improved Naïve Bayes               0.815014           0.659494"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So as we can see the Improved NaiveBayes algorithm, after performing lemmatization, removing stopwords, using bigrams and using laplace smoothing has some *'litle'* but still there is improvement!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part - Of - Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\" Map POS tag to first character lemmatize() accepts. \"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will provide the correct 'part-of-speech' tag as the second argument to lemmatize(). That way our Comment column of the dataframe will have the pos tags (features) of the whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3586                                  [love, chick, voic]\n",
       "231                              [oh, hey, yousaid, like]\n",
       "1119                                        [fuck, idiot]\n",
       "3330    [photograph, avoid, urg, steal, brink, ?, woul...\n",
       "968     [know, work, lot, countri, europ, brazil, isre...\n",
       "Name: Comment, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize(tokens):\n",
    "    \"\"\" Lemmatize all words in given list of tokens. \"\"\"\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lems = [lemmatizer.lemmatize(token, get_wordnet_pos(token))\n",
    "            for token in tokens]\n",
    "\n",
    "    return lems\n",
    "\n",
    "\n",
    "x_train = x_train.apply(lambda x: lemmatize(x))\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4    [0.0, 0.0, 0.0, 0.0, 0.21913705030672145, 0.20...\n",
       "dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dummy(doc):\n",
    "    \"\"\" Dummy tokenizer to use when data are already tokenized. \"\"\"\n",
    "    return doc\n",
    "\n",
    "def tf_idf(series):\n",
    "    \"\"\" Tf-Idf vectorization of Comments. Return a series of the vectors. \"\"\"\n",
    "\n",
    "    comment_list = series.tolist()\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        tokenizer=dummy, preprocessor=dummy, max_features=222)\n",
    "\n",
    "    matr = tfidf_vectorizer.fit_transform(comment_list)\n",
    "    ser = pd.Series(matr.toarray().tolist())\n",
    "    # return series of vectors for Comments\n",
    "    return ser\n",
    "\n",
    "\n",
    "tfidf_train_pos = tf_idf(x_train) \n",
    "tfidf_test_pos = tf_idf(x_test)\n",
    "tfidf_train_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3157,)\n",
      "(790,)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_train_pos.shape)\n",
    "print(tfidf_test_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF - IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **This one will not be in use, as we have made above tf-idf representation given the pos-tags of the text data, so we'll use them combined on our models below as we won't get any better improvement testing tf-idf features alone!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since the project definition needs the code implementation of both pos and tf-df seperataly, i'm providing my code of the 2nd project on tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range3 = (1,2)\n",
    "min_df3 = 10\n",
    "max_df3 = 1.\n",
    "max_features3 = 222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3157, 222)\n",
      "(790, 222)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range3,\n",
    "                        stop_words=stop_words,\n",
    "                        lowercase=True,\n",
    "                        max_df=max_df3,\n",
    "                        min_df=min_df3,\n",
    "                        max_features=max_features3,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "tf_idf_train = tfidf.fit_transform(x_train.astype('U')).toarray()\n",
    "print(tf_idf_train.shape)\n",
    "\n",
    "tf_idf_test = tfidf.transform(x_test.astype('U')).toarray()\n",
    "print(tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we got our POS tags and our TF-IDF representation, we'll try them on SVM & Random Decision Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Made them as lists to prevent the error: setting an array element with a sequence\n",
    "tfidf_trainpos = list(tfidf_train_pos)\n",
    "tfidf_testpos = list(tfidf_test_pos)\n",
    "Labels_train = list(labels_train)\n",
    "Labels_test = list(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=8, test_size=0.22, train_size=None),\n",
       "             error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=8, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated'...one,\n",
       "             param_grid=[{'C': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['linear'],\n",
       "                          'probability': [True]},\n",
       "                         {'C': [0.0001, 0.001, 0.01, 0.1], 'degree': [3, 4, 5],\n",
       "                          'kernel': ['poly'], 'probability': [True]},\n",
       "                         {'C': [0.0001, 0.001, 0.01, 0.1],\n",
       "                          'gamma': [1, 10, 100], 'kernel': ['rbf'],\n",
       "                          'probability': [True]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = [.0001, .001, .01, .1]\n",
    "degree = [3, 4, 5]\n",
    "gamma = [1, 10, 100]\n",
    "probability = [True]\n",
    "\n",
    "param_grid = [\n",
    "  {'C': C, 'kernel':['linear'], 'probability':probability},\n",
    "  {'C': C, 'kernel':['poly'], 'degree':degree, 'probability':probability},\n",
    "  {'C': C, 'kernel':['rbf'], 'gamma':gamma, 'probability':probability}\n",
    "]\n",
    "\n",
    "# Create a base model\n",
    "svc = svm.SVC(random_state=8)\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .22, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=svc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(tfidf_trainpos, Labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Grid Search are:\n",
      "{'C': 0.1, 'kernel': 'linear', 'probability': True}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.7863309352517985\n"
     ]
    }
   ],
   "source": [
    "# best hyperparameters: \n",
    "\n",
    "print(\"The best hyperparameters from Grid Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=8, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the model as best_svc:\n",
    "\n",
    "best_svc = grid_search.best_estimator_\n",
    "best_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=8, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc.fit(tfidf_trainpos, Labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = best_svc.predict(tfidf_testpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.7427937915742794\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(Labels_train, best_svc.predict(tfidf_trainpos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: \n",
      "0.730379746835443\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(Labels_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84       585\n",
      "           1       0.25      0.02      0.04       205\n",
      "\n",
      "    accuracy                           0.73       790\n",
      "   macro avg       0.50      0.50      0.44       790\n",
      "weighted avg       0.61      0.73      0.63       790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(Labels_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create a dataset with a model summary to compare models:\n",
    "\n",
    "d = {\n",
    "     'Model': 'SVM',\n",
    "     'Training Set Accuracy': accuracy_score(Labels_train, best_svc.predict(tfidf_trainpos)),\n",
    "     'Test Set Accuracy': accuracy_score(Labels_test, svc_pred)\n",
    "}\n",
    "\n",
    "df_models_svc = pd.DataFrame(d, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.742794</td>\n",
       "      <td>0.73038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Training Set Accuracy  Test Set Accuracy\n",
       "0   SVM               0.742794            0.73038"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_models_svc.pickle', 'wb') as output:\n",
    "    pickle.dump(df_models_svc, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 8,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters for Random Forest: \n",
    "\n",
    "\n",
    "rf_0 = RandomForestClassifier(random_state = 8)\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "rf_0.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [200, 400, 600, 800, 1000],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'max_depth': [20, 40, 60, 80, 100, None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_estimators\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)]\n",
    "\n",
    "# max_features\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# max_depth\n",
    "max_depth = [int(x) for x in np.linspace(20, 100, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# min_samples_split\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# min_samples_leaf\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# bootstrap\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:  8.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=8, test_size=0.22, train_size=None),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_sampl...\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=8,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'bootstrap': [False], 'max_depth': [30, 40, 50],\n",
       "                         'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [800]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search: \n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "bootstrap = [False]\n",
    "max_depth = [30, 40, 50]\n",
    "max_features = ['sqrt']\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "min_samples_split = [5, 10, 15]\n",
    "n_estimators = [800]\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': bootstrap,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'n_estimators': n_estimators\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rfc = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .22, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rfc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(tfidf_trainpos, Labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Grid Search are:\n",
      "{'bootstrap': False, 'max_depth': 40, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 15, 'n_estimators': 800}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.8244604316546763\n"
     ]
    }
   ],
   "source": [
    "print(\"The best hyperparameters from Grid Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=40, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=15,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=800,\n",
       "                       n_jobs=None, oob_score=False, random_state=8, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc = grid_search.best_estimator_\n",
    "best_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=40, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=15,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=800,\n",
       "                       n_jobs=None, oob_score=False, random_state=8, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc.fit(tfidf_trainpos, Labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = best_rfc.predict(tfidf_testpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.8584098828001268\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(Labels_train, best_rfc.predict(tfidf_trainpos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: \n",
      "0.6708860759493671\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(Labels_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       585\n",
      "           1       0.31      0.21      0.25       205\n",
      "\n",
      "    accuracy                           0.67       790\n",
      "   macro avg       0.53      0.52      0.52       790\n",
      "weighted avg       0.64      0.67      0.65       790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(Labels_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.85841</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Training Set Accuracy  Test Set Accuracy\n",
       "0  Random Forest                0.85841           0.670886"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "     'Model': 'Random Forest',\n",
    "     'Training Set Accuracy': accuracy_score(Labels_train, best_rfc.predict(tfidf_trainpos)),\n",
    "     'Test Set Accuracy': accuracy_score(Labels_test, rfc_pred)\n",
    "}\n",
    "\n",
    "df_models_rfc = pd.DataFrame(d, index=[0])\n",
    "df_models_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_models_rfc.pickle', 'wb') as output:\n",
    "    pickle.dump(df_models_rfc, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pickles = \"/home/andrewpap22/Desktop/dataMining_MainProject/\"\n",
    "\n",
    "list_pickles = [\n",
    "    \"df_models_mnbc.pickle\",\n",
    "    \"df_models_mnbc2.pickle\",\n",
    "    \"df_models_svc.pickle\",\n",
    "    \"df_models_rfc.pickle\"\n",
    "]\n",
    "\n",
    "df_summary2 = pd.DataFrame()\n",
    "\n",
    "for pickle_ in list_pickles:\n",
    "    \n",
    "    path = path_pickles + pickle_\n",
    "    \n",
    "    with open(path, 'rb') as data:\n",
    "        df = pickle.load(data)\n",
    "\n",
    "    df_summary2 = df_summary2.append(df)\n",
    "\n",
    "df_summary2 = df_summary2.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic Naïve Bayes</td>\n",
       "      <td>0.770035</td>\n",
       "      <td>0.649367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Improved Naïve Bayes</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.659494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.742794</td>\n",
       "      <td>0.730380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.858410</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training Set Accuracy  Test Set Accuracy\n",
       "0     Basic Naïve Bayes               0.770035           0.649367\n",
       "1  Improved Naïve Bayes               0.815014           0.659494\n",
       "2                   SVM               0.742794           0.730380\n",
       "3         Random Forest               0.858410           0.670886"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by: **Test Set Accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.742794</td>\n",
       "      <td>0.730380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.858410</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Improved Naïve Bayes</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.659494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic Naïve Bayes</td>\n",
       "      <td>0.770035</td>\n",
       "      <td>0.649367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training Set Accuracy  Test Set Accuracy\n",
       "2                   SVM               0.742794           0.730380\n",
       "3         Random Forest               0.858410           0.670886\n",
       "1  Improved Naïve Bayes               0.815014           0.659494\n",
       "0     Basic Naïve Bayes               0.770035           0.649367"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary2.sort_values('Test Set Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: \n",
    "\n",
    "**F1-Scores:**\n",
    "\n",
    "1. SVM: **0.84**\n",
    "2. Random Forest: **0.79**\n",
    "3. Improved Naive Bayes: **0.78**\n",
    "4. Basic Naive Bayes: **0.73** \n",
    "\n",
    "So as we can see: \n",
    "\n",
    "**SVM** is the best model so far with the best performance and scores!!! \n",
    "\n",
    "The reason is, we gave it the best possible features and best possible cleaned data (best possible by what i could personally manage... not to mean the best possible created!) \n",
    "It contained the full cleaned data with the extra cleaning we did for the Improved Naive bayes + the combination of tfidf and pos tag features. So, that's a good reason why SVM has the best test set accuracy and f1-score! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-----------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Now we'll try anything we can in order to get the best possible Test Set Accuracy and F1-Score__* \n",
    "\n",
    "i.e. We have to exceed the performance of SVM! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i) Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': [0.1,\n",
       "  0.2,\n",
       "  0.30000000000000004,\n",
       "  0.4,\n",
       "  0.5,\n",
       "  0.6,\n",
       "  0.7000000000000001,\n",
       "  0.8,\n",
       "  0.9,\n",
       "  1.0],\n",
       " 'multi_class': ['multinomial'],\n",
       " 'solver': ['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
       " 'class_weight': ['balanced', None],\n",
       " 'penalty': ['l2']}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomized search cross validation:\n",
    "\n",
    "# C\n",
    "C = [float(x) for x in np.linspace(start = 0.1, stop = 1, num = 10)]\n",
    "\n",
    "# multi_class\n",
    "multi_class = ['multinomial']\n",
    "\n",
    "# solver\n",
    "solver = ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
    " \n",
    "# class_weight\n",
    "class_weight = ['balanced', None]\n",
    "\n",
    "# penalty\n",
    "penalty = ['l2']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'C': C,\n",
    "               'multi_class': multi_class,\n",
    "               'solver': solver,\n",
    "               'class_weight': class_weight,\n",
    "               'penalty': penalty}\n",
    "\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:   36.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='auto', n_jobs=None,\n",
       "                                                penalty='l2', random_state=8,\n",
       "                                                solver='lbfgs', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='deprecated', n_iter=50, n_jobs=None,\n",
       "                   param_distributions={'C': [0.1, 0.2, 0.30000000000000004,\n",
       "                                              0.4, 0.5, 0.6, 0.7000000000000001,\n",
       "                                              0.8, 0.9, 1.0],\n",
       "                                        'class_weight': ['balanced', None],\n",
       "                                        'multi_class': ['multinomial'],\n",
       "                                        'penalty': ['l2'],\n",
       "                                        'solver': ['newton-cg', 'sag', 'saga',\n",
       "                                                   'lbfgs']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=8, refit=True,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The search:\n",
    "\n",
    "# First create the base model to tune\n",
    "lrc = LogisticRegression(random_state=8)\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=lrc,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(tf_idf_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'multinomial', 'class_weight': None, 'C': 0.7000000000000001}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.8175473660264535\n"
     ]
    }
   ],
   "source": [
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.7000000000000001, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
       "                   penalty='l2', random_state=8, solver='newton-cg', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lrc = random_search.best_estimator_\n",
    "best_lrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.7000000000000001, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
       "                   penalty='l2', random_state=8, solver='newton-cg', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lrc.fit(tf_idf_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc_pred = best_lrc.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.835920177383592\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, best_lrc.predict(tf_idf_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: \n",
      "0.8265822784810126\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, lrc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       585\n",
      "           1       0.76      0.49      0.59       205\n",
      "\n",
      "    accuracy                           0.83       790\n",
      "   macro avg       0.80      0.72      0.74       790\n",
      "weighted avg       0.82      0.83      0.81       790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,lrc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.83592</td>\n",
       "      <td>0.826582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Set Accuracy  Test Set Accuracy\n",
       "0  Logistic Regression                0.83592           0.826582"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "     'Model': 'Logistic Regression',\n",
    "     'Training Set Accuracy': accuracy_score(labels_train, best_lrc.predict(tf_idf_train)),\n",
    "     'Test Set Accuracy': accuracy_score(labels_test, lrc_pred)\n",
    "}\n",
    "\n",
    "df_models_lrc = pd.DataFrame(d, index=[0])\n",
    "df_models_lrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_models_lrc.pickle', 'wb') as output:\n",
    "    pickle.dump(df_models_lrc, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results & Conclusion!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pickles = \"/home/andrewpap22/Desktop/dataMining_MainProject/\"\n",
    "\n",
    "list_pickles = [\n",
    "    \"df_models_mnbc.pickle\",\n",
    "    \"df_models_mnbc2.pickle\",\n",
    "    \"df_models_svc.pickle\",\n",
    "    \"df_models_rfc.pickle\",\n",
    "    \"df_models_lrc.pickle\"\n",
    "]\n",
    "\n",
    "df_summary_final = pd.DataFrame()\n",
    "\n",
    "for pickle_ in list_pickles:\n",
    "    \n",
    "    path = path_pickles + pickle_\n",
    "    \n",
    "    with open(path, 'rb') as data:\n",
    "        df = pickle.load(data)\n",
    "\n",
    "    df_summary_final = df_summary_final.append(df)\n",
    "\n",
    "df_summary_final = df_summary_final.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic Naïve Bayes</td>\n",
       "      <td>0.770035</td>\n",
       "      <td>0.649367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Improved Naïve Bayes</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.659494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.742794</td>\n",
       "      <td>0.730380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.858410</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.835920</td>\n",
       "      <td>0.826582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training Set Accuracy  Test Set Accuracy\n",
       "0     Basic Naïve Bayes               0.770035           0.649367\n",
       "1  Improved Naïve Bayes               0.815014           0.659494\n",
       "2                   SVM               0.742794           0.730380\n",
       "3         Random Forest               0.858410           0.670886\n",
       "4   Logistic Regression               0.835920           0.826582"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by: **Test Set Accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.835920</td>\n",
       "      <td>0.826582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.742794</td>\n",
       "      <td>0.730380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.858410</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Improved Naïve Bayes</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.659494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic Naïve Bayes</td>\n",
       "      <td>0.770035</td>\n",
       "      <td>0.649367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training Set Accuracy  Test Set Accuracy\n",
       "4   Logistic Regression               0.835920           0.826582\n",
       "2                   SVM               0.742794           0.730380\n",
       "3         Random Forest               0.858410           0.670886\n",
       "1  Improved Naïve Bayes               0.815014           0.659494\n",
       "0     Basic Naïve Bayes               0.770035           0.649367"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_final.sort_values('Test Set Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Summary: \n",
    "\n",
    "**F1-Scores:**\n",
    "\n",
    "1. *SVM*: **0.84**\n",
    "2. *Random Forest*: **0.79**\n",
    "3. *Improved Naive Bayes*: **0.78**\n",
    "4. *Basic Naive Bayes*: **0.73** \n",
    "5. *Multinomial Logistic Regresion*: **0.89**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we can see: \n",
    "\n",
    "We got much better results on **Multinomial Logistic Regresion** compared to the previous best: *SVM* with a much higher **Test Set Accuracy** and slightly higher **F1-Score**! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did on Logistic Regresion is: \n",
    "\n",
    "We transformed the firstly cleaned data (cl_data) into tf-idf features, we had already previously done, lemmatization, removed the stop words and we have used bigrams as well but we did not pass the pos tags as well, as we did with the previous models. We have just passed the tf-idf features alone and that resulted in much better results in the Logistic Regresion model, BUT when tf-idf features tested alone without the pos tags in the previous models, it did not result in better Test Set Accuracy nor F1-Score! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here the project is complete! \n",
    "\n",
    "**Thank you!** \n",
    "\n",
    "*Author:* **Andreas Pappas** \n",
    "*ID:* **1115201500201** \n",
    "\n",
    "Spring Semester 2020 \n",
    "Data Mining Course!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
